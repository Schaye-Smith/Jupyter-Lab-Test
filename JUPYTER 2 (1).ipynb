{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# My Jupyter Notebook on IBM Watson Studio"}, {"metadata": {}, "cell_type": "markdown", "source": "__Schaye Bedell-Smith__ \nI am currently studying to become a Data Scientist."}, {"metadata": {}, "cell_type": "markdown", "source": "*I am interested in Data Science because I love analyzing data.*"}, {"metadata": {}, "cell_type": "markdown", "source": "Below is data collected from the JFK airport that is displayed through Spark Session Dataframe"}, {"metadata": {}, "cell_type": "code", "source": "\nimport ibmos2spark, os\n# @hidden_cell\ncredentials = {\n    'endpoint': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx',\n    'service_id': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx',\n    'iam_service_endpoint': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx',\n    'api_key': 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n}\n\nconfiguration_name = 'os_cdc1188d05e349a6be6c71da8e6f5192_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\ndf_data_1 = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('jfk_weather_sample.csv', 'courseratest1-donotdelete-pr-hm90jl2ouunqb2'))\ndf_data_1.take(5)\n", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "[Row(DATE='2015-07-25T13:51:00Z', HOURLYDewPointTempF='60', HOURLYRelativeHumidity='46', HOURLYDRYBULBTEMPF='83', HOURLYWETBULBTEMPF='68', HOURLYPrecip='0.00', HOURLYWindSpeed='13', HOURLYSeaLevelPressure='30.01', HOURLYStationPressure='29.99'),\n Row(DATE='2016-11-18T23:51:00Z', HOURLYDewPointTempF='34', HOURLYRelativeHumidity='48', HOURLYDRYBULBTEMPF='53', HOURLYWETBULBTEMPF='44', HOURLYPrecip='0.00', HOURLYWindSpeed='6', HOURLYSeaLevelPressure='30.05', HOURLYStationPressure='30.03'),\n Row(DATE='2013-01-06T08:51:00Z', HOURLYDewPointTempF='33', HOURLYRelativeHumidity='89', HOURLYDRYBULBTEMPF='36', HOURLYWETBULBTEMPF='35', HOURLYPrecip='0.00', HOURLYWindSpeed='13', HOURLYSeaLevelPressure='30.14', HOURLYStationPressure='30.12'),\n Row(DATE='2011-01-27T16:51:00Z', HOURLYDewPointTempF='18', HOURLYRelativeHumidity='48', HOURLYDRYBULBTEMPF='36', HOURLYWETBULBTEMPF='30', HOURLYPrecip='0.00', HOURLYWindSpeed='14', HOURLYSeaLevelPressure='29.82', HOURLYStationPressure='29.8'),\n Row(DATE='2015-01-03T12:16:00Z', HOURLYDewPointTempF='27', HOURLYRelativeHumidity='61', HOURLYDRYBULBTEMPF='39', HOURLYWETBULBTEMPF='34', HOURLYPrecip='T', HOURLYWindSpeed='11', HOURLYSeaLevelPressure='NA', HOURLYStationPressure='30.5')]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "https://youtu.be/dQw4w9WgXcQ   \nhttps://youtu.be/dQw4w9WgXcQ\nhttps://youtu.be/dQw4w9WgXcQ"}], "metadata": {"kernelspec": {"name": "python39", "display_name": "Python 3.9 with Spark", "language": "python3"}, "language_info": {"name": "python", "version": "3.9.7", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}